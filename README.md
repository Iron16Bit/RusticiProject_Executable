# Rustici Project

Welcome to the Rustici Project!

## Group Members
- [Federico Menegoz](https://github.com/FedericoMenegoz)
- [Salvatore Gilles Cassar√†](https://github.com/Iron16Bit)
- [Alberto Cimmino](https://github.com/bettozzo)

## Building and Running the App

Simply run the `rustici_app` executable file.
Unfortunately we can't share the source code, so the only way to try the program is using a Windows machine.

## AI (Salvatore Gilles Cassar√† 227202)

The brain of our robot: an AI created using reinforcement learning.
In particular, it uses the q-learning algorithm which, given a set of states the robot can be in, a set of actions it can execute and a reward function that rewards the correct actions made by the robot, tries the best way to concatenate states and actions in order to reach its goal: make money.

### Q-Learning

Evrything revolves around the q-learning function:

Qn(S, A) = (1 - Œ±) * Q(S, A) + Œ± * (reward * Œ≥ * estimated_reward(S))

Where:
- Œ± is called _learning rate_: how much newly learned information affect the old knowledge
- Œ≥ is called _discount factor_: how much the maximum estimated reward of the current state affects the choice of an action
- _estimated_reward(S)_: simply retarns the maximum obtainable reward given the current state

Through training, these values are optimized, improving the AI's performance.

## Visualizer 1 (Federico Menegoz (WG) 228394)

**Note:** At the moment it looks like this visualizer isn't working properly.

Visualizer that either showcases a pre-trained robot completing its mission or allows you to train a robot by fine-tuning the rewards of the q-learning algorithm. Developed using Bevy Game Engine.

### Getting Started üèÅ

Simply click on "Start" from the main menu! This will prompt the AI to compute the data and initiate the simulation. The default settings are:

- World size: 200
- Pre-trained robot

### Settings üõ†Ô∏è

In the main menu, click on "Settings". In the settings window, you can view and change the size and the bot you would like to use.

### Training üèãÔ∏è

Click on the "Training" button and adjust the rewards as you prefer for each state. The values displayed here are the ones used to train the default robot. Once you are satisfied with the rewards you've set, simply click "Exit and Train" and wait for your bot's training to finish. A delightful tune will accompany you through the process.
If after training you want to test your robot:

1. Open the visualizer.
2. Click on "Settings".
3. Select the custom robot.
4. Return to the main menu.
5. Click "Start".
6. If the robot seems a bit slow or inefficient, don't worry! It just needs more training and attention.

### Rustici Tool & WG üé≠

Click on the "Rustici Tool & WG" to get an idea of our Planner Tool and World Generator.
Here, a simple AI will utilize our tool to explore the map and collect resources (üêüüå≥ü™®ü™ôüóëÔ∏è), always choosing the most cost-effective path.
In the [Tool & WG], you can click on 'Test!':

- With no biome type selected, it will spawn the bot on a 10x10 test world to demonstrate a deterministic outcome.
- With a biome selected, it will spawn the bot on our World Generator using that particular biome type.

### Simulation Keyboard Control

- ‚¨ÜÔ∏è: Music Volume Up
- ‚¨áÔ∏è: Music Volume Down
- ‚û°Ô∏è: Robot Moves Faster
- ‚¨ÖÔ∏è: Robot Moves Slower
- 'P': Show All Map (the Robot will explore by the end of the simulation)
- 'O': Hide All Map (not yet explored)
- 'SPACE': Zoom In
- '-': Zoom Out

## Visualizer 2 (Alberto Cimmino 226899)

This is a visualizer that showcases a pre-trained robot completing its mission. It was developed using the crate Macroquad. It's a 3D enviorement with 2D sprites.

### Simulation Keyboard Control

- ‚û°Ô∏è: Robot Moves Faster
- ‚¨ÖÔ∏è: Robot Moves Slower
- F : Toggle between Free-Camera Mode and Following-Robot Mode.
- While in Free-Camera Mode
  - WASD, Ctrl and space to move freely
  - Mouse to control the view
